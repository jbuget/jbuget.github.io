---
title: "Faire de la recherche hybride avec Meilisearch"
draft: false
date: "2025-08-28T09:00:00+02:00"
---

Je continue de creuser [**Meilisearch**](https://www.meilisearch.com), le moteur de recherche hybride (full-text et IA-powered) open-source, alternative √† Algolia, Typesense et Elasticsearch. Dans cet article, nous allons voir comment d√©finir et alimenter un index avec pr√®s de 90K documents depuis un fichier de donn√©es JSON r√©cup√©r√© sur data.gouv.fr (il y a un peu de taff),  comment mettre en place la recherche mixte (textuelle + vectorielle) et ce que √ßa donne comme r√©sultat.

## 1. Faire tourner une instance Meilisearch avec Docker

```yaml
services:
  meilisearch:
    image: getmeili/meilisearch:v1.19
    container_name: meilisearch
    restart: unless-stopped
    ports:
      - "7700:7700"
    environment:
      MEILI_MASTER_KEY: "myMasterKey"   # √† personnaliser
    volumes:
      - meili_data:/meili_data
    command: meilisearch --experimental-dumpless-upgrade

volumes:
  meili_data:
```

Dans Meilisearch (version Community Edition), toute l'administration se passe en ligne de commande (CLI ou API HTTP). Personnellement, mon moyen de pr√©dilection est de faire des requ√™tes HTTP avec `cURL` et `jq` (pour formatter et manipuler les donn√©es JSON en r√©ponse).

> üí° Avec cURL, j'utilise l'option `-s | --silent` afin de ne pas √™tre pollu√© par les informations de progression de r√©cup√©ration des donn√©es.

Pour toute requ√™te de l'API Meilisearch, il faut passer la master key en header `AUTHORIZATION` #s√©curit√©.
{.pros}

```shell
$ curl -s -X GET 'localhost:7700/indexes' \
  -s -H "Authorization: Bearer myMasterKey" \
  | jq

> {
  "results": [
    {
      "uid": "services",
      "createdAt": "2025-08-28T10:34:15.425435597Z",
      "updatedAt": "2025-08-28T10:34:43.891700971Z",
      "primaryKey": "safe_id"
    }
  ],
  "offset": 0,
  "limit": 20,
  "total": 1
}
```




## 2. R√©cup√©rer les donn√©es

Pour notre cas d'√©tude, j'ai d√©cid√© d'exploiter des donn√©es que je connais bien : l'ensemble des **services d'insertion socio-professionnelles** ‚Äì alias "offre des services de l'inclusion" ‚Äì r√©f√©renc√©s par la Plateforme de l'inclusion, et r√©guli√®rement mis √† jour et √† disposition dans la plateforme de l'√©tat data.gouv.fr (cf. lien vers le fichier de donn√©es). Pour compl√©ter un peu plus l'exp√©rience et aller un cran plus loin, je vais aussi r√©cup√©rer les donn√©es des **structures de l'inclusion**.

Les 2 sources de donn√©es en question :
* [liste des services](https://www.data.gouv.fr/datasets/referentiel-de-loffre-dinsertion-sociale-et-professionnelle-data-inclusion/#/resources/0eac1faa-66f9-4e49-8fb3-f0721027d89f) ‚Äì +80K documents / 235Mo
  * **~/Downloads/services-inclusion-2025-08-25.json**
* [liste des structures](https://www.data.gouv.fr/datasets/referentiel-de-loffre-dinsertion-sociale-et-professionnelle-data-inclusion/#/resources/0eac1faa-66f9-4e49-8fb3-f0721027d89f) ‚Äì +60K documents / 101Mo
  * **~/Downloads/structures-inclusion-2025-08-25.json**

![Donn√©es de data¬∑inclusion depuis data.gouv.fr](data-gouv-di-services.png)

## 3. D√©clarer les indexes

√Ä ce stade, nous disposons du contenant (Meilisearch) et d'un contenu (gros fichier JSON). Le prochain objectif est d'injecter les donn√©es (services et structures) dans le syst√®me.

Pour cela, nous d√©finissons 2 indexes : `/services` et `structures`.

> üí° Dans Meilisearch (et plus g√©n√©ralement dans les syst√®mes de moteur de recherche), **un index est une base de donn√©es optimis√©e pour la recherche, qui regroupe des documents partageant la m√™me structure** et sur laquelle on ex√©cute les requ√™tes full-text, vectorielles ou hybrides.

Dans Meilisearch (version Community Edition), toute l'administration se passe en ligne de commande (CLI ou requ√™tes HTTP / cURL). Personnellement, je passe pas

De fa√ßon pratique, Meilisearch cr√©√©e automatiquement un index s'il n'existe pas au moment d'injecter des documents. Personnellement, je pr√©f√®re d√©clarer les indexes moi-m√™me, car je pr√©f√®re avoir le contr√¥le et que d√®s que l'on utilise r√©ellement la solution, il faut le plus souvent, √† un moment ou un autre, param√©trer l'index.
{.pros}

La commande pour **d√©clarer un index** :

```shell
$ curl -s -X POST 'http://localhost:7700/indexes' \
  -H "Authorization: Bearer myMasterKey" \
  -H 'Content-Type: application/json' \
  --data '{"uid":"services","primaryKey":"id"}' \
  | jq

> {
  "taskUid": 19,
  "indexUid": "services",
  "status": "enqueued",
  "type": "indexCreation",
  "enqueuedAt": "2025-08-28T16:08:21.677341712Z"
}
```

En cas de probl√®me ou d'erreur, il est possible de **supprimer un index** gr√¢ce √† la ressource `DELETE /indexes/{index_name}` :

```shell
$ curl -s -X DELETE 'http://localhost:7700/indexes/services' \
  -H "Authorization: Bearer myMasterKey" \
  | jq

> {
  "taskUid": 16,
  "indexUid": "services",
  "status": "enqueued",
  "type": "indexDeletion",
  "enqueuedAt": "2025-08-28T16:03:56.477857464Z"
}
```

Apr√®s la cr√©ation des 2 indexes, le listing des indexes devrait ressembler √† :

```shell
$ curl -s -X GET 'localhost:7700/indexes' -H "Authorization: Bearer myMasterKey" | jq

> {
  "results": [
    {
      "uid": "services",
      "createdAt": "2025-08-28T16:08:21.680481753Z",
      "updatedAt": "2025-08-28T16:08:21.685127462Z",
      "primaryKey": "id"
    },
    {
      "uid": "structures",
      "createdAt": "2025-08-28T16:08:13.975849291Z",
      "updatedAt": "2025-08-28T16:08:13.983862708Z",
      "primaryKey": "id"
    }
  ],
  "offset": 0,
  "limit": 20,
  "total": 2
}
```

Tout est pr√™t pour importer notre premier jeu de donn√©es, les services.

## 4. Injecter les donn√©es

Pour **injecter des documents dans un index**, il faut utiliser la commande :

```shell
$ curl -X POST 'http://localhost:7700/indexes/services/documents' \
  -H "Authorization: Bearer myMasterKey" \
  -H 'Content-Type: application/json' \
  --data-binary "@${HOME}/Downloads/services-inclusion-2025-08-25.json" \
  | jq

> {
  "taskUid": 21,
  "indexUid": "services",
  "status": "enqueued",
  "type": "documentAdditionOrUpdate",
  "enqueuedAt": "2025-08-28T16:20:26.170638547Z"
}
```

Toujours dans un souci de simplifier la vie des d√©veloppeurs, Meilisearch tente de d√©tecter un champs ID pour en faire la `primaryKey` de l'index. Il se trouve que le sch√©ma de notre jeu de donn√©es poss√®de d√©j√† un champs ID. Tout devrait bien se passer. Pour s'en assurer, on peut lire le d√©but du fichier de donn√©es :
{.pros}

```shell
$ head -c 1000 ~/Downloads/services-inclusion-2025-08-25.json

> [{"id":"Mednum-BFC_mednumBFC_TL_206_-mediation-numerique","structure_id":"Mednum-BFC_mednumBFC_TL_206_","source":"mediation-numerique","nom":"M√©diation num√©rique","presentation_resume":"Le V  Fourmili√®re des Savoir-Faire propose des services : num√©rique, accompagner les d√©marches de sant√©, devenir autonome dans les d√©marches administratives, r√©aliser des d√©marches administratives avec un accompagnement.","presentation_detail":"Le V  Fourmili√®re des Savoir-Faire propose des services : num√©rique, accompagner les d√©marches de sant√©, devenir autonome dans les d√©marches administratives, r√©aliser des d√©marches administratives avec un accompagnement.","types":["accompagnement"],"thematiques":["numerique","numerique--realiser-des-demarches-administratives-avec-un-accompagnement","numerique--devenir-autonome-dans-les-demarches-administratives","numerique--accompagner-les-demarches-de-sante"],"prise_rdv":null,"frais":[],"frais_autres":null,"profils":[],"profils_precisions":null,"%
```

La commande `POST /indexes/services/documents` s'est finie sans afficher aucune erreur. On pourrait donc se satisfaire que tout a fonctionn√© du premier coup. Malheureusement, ce n'est pas le cas üò©.

Chaque op√©ration effectu√©e dans Meilisearch prend la forme d'une `Task`, avec diff√©rents statuts, qu'il est possible de suivre :

```shell
$ curl -s -X GET 'localhost:7700/tasks' -H "Authorization: Bearer myMasterKey" | jq

> {
  "results": [
    {
      "uid": 21,
      "batchUid": 19,
      "indexUid": "services",
      "status": "failed",
      "type": "documentAdditionOrUpdate",
      "canceledBy": null,
      "details": {
        "receivedDocuments": 86670,
        "indexedDocuments": 0
      },
      "error": {
        "message": "Document identifier `\"Coop-num√©rique_1a162d63-e303-4fdc-aa08-71d47634b1ff-mediation-numerique\"` is invalid. A document identifier can be of type integer or string, only composed of alphanumeric characters (a-z A-Z 0-9), hyphens (-) and underscores (_), and can not be more than 511 bytes.",
        "code": "invalid_document_id",
        "type": "invalid_request",
        "link": "https://docs.meilisearch.com/errors#invalid_document_id"
      },
      "duration": "PT0.001194792S",
      "enqueuedAt": "2025-08-28T16:20:26.170638547Z",
      "startedAt": "2025-08-28T16:20:26.17297113Z",
      "finishedAt": "2025-08-28T16:20:26.174165922Z"
    },
    # ...
  ]
}
```

‚ùå Il y a eu un souci lors de l'import des donn√©es. L'une des entr√©es poss√®de des accents dans son ID.

Pas le choix, il faut faire un script pour "adapter les donn√©es". Je n'ai pas envie de me prendre la t√™te, je demande √† Claude de me le cr√©er, en Node.js. Pr√©cis√©ment, je lui demande de g√©n√©rer un `safe_id` de type UUID pour chacun des objets "services".

```javascript
#!/usr/bin/env node
/**
 * make-services-clean.js
 * Lit un gros JSON (tableau) en streaming, ajoute safe_id=UUIDv4 √† chaque objet,
 * et produit un nouveau fichier JSON (tableau) sans charger tout le fichier en RAM.
 *
 * Usage:
 *   node make-services-clean.js \
 *     --in ~/Downloads/services-inclusion-2025-08-25.json \
 *     --out ~/Downloads/services-clean.json
 */

const fs = require('fs');
const path = require('path');
const { pipeline } = require('stream');
const { randomUUID } = require('crypto');
const { parser } = require('stream-json');
const { streamArray } = require('stream-json/streamers/StreamArray');

function expandHome(p) {
  if (p.startsWith('~/')) return path.join(process.env.HOME || process.env.USERPROFILE || '', p.slice(2));
  return p;
}

function getArg(flag, def = null) {
  const idx = process.argv.indexOf(flag);
  return idx !== -1 && process.argv[idx + 1] ? process.argv[idx + 1] : def;
}

const inPath = expandHome(getArg('--in', '~/Downloads/services-inclusion-2025-08-25.json'));
const outPath = expandHome(getArg('--out', '~/Downloads/services-clean.json'));

// V√©rifs rapides
if (!fs.existsSync(inPath)) {
  console.error(`Fichier introuvable: ${inPath}`);
  process.exit(1);
}

// Flux lecture JSON + parseur + streamer d'√©l√©ments de tableau
const readStream = fs.createReadStream(inPath, { encoding: 'utf8' });
const jsonParser = parser();
const arrayStreamer = streamArray();

// √âcriture en flux du tableau de sortie
const writeStream = fs.createWriteStream(outPath, { encoding: 'utf8' });

// On √©crit l'ouverture du tableau
writeStream.write('[');

let first = true;
let count = 0;

// √Ä chaque √©l√©ment {key, value} du tableau d'entr√©e
arrayStreamer.on('data', ({ value }) => {
  // Ajout d‚Äôun UUID v4
  value.safe_id = randomUUID();

  // √âcrire la virgule entre √©l√©ments (sauf le premier)
  if (!first) {
    writeStream.write(',');
  } else {
    first = false;
  }

  // √âcriture compacte pour limiter la taille du fichier
  writeStream.write(JSON.stringify(value));
  count++;
});

// Gestion fin et erreurs
arrayStreamer.on('end', () => {
  writeStream.write(']');
  writeStream.end(() => {
    console.log(`OK ‚úÖ  ${count} objets trait√©s`);
    console.log(`‚Üí Fichier √©crit : ${outPath}`);
  });
});

arrayStreamer.on('error', (err) => {
  console.error('Erreur streamArray:', err);
  process.exit(1);
});

jsonParser.on('error', (err) => {
  console.error('Erreur parser JSON:', err);
  process.exit(1);
});

writeStream.on('error', (err) => {
  console.error('Erreur √©criture fichier:', err);
  process.exit(1);
});

// Cha√Æner les streams
pipeline(readStream, jsonParser, arrayStreamer, (err) => {
  if (err) {
    console.error('Erreur pipeline:', err);
    process.exit(1);
  }
});
```


Pour l'ex√©cution :

```shell
# 1. On installe les d√©pendances npm
$ npm i stream-json

# 2. On ex√©cute le programme
$ node make-services-clean.js \
  --in ~/Downloads/services-inclusion-2025-08-25.json \
  --out ~/Downloads/services-clean.json

> OK ‚úÖ  86670 objets trait√©s
‚Üí Fichier √©crit : /Users/vous/Downloads/services-clean.json
```

‚ö†Ô∏è Il faut reg√©n√©rer l'index "services" :

```shell
$ curl -s -X DELETE 'http://localhost:7700/indexes/services' \
  -H "Authorization: Bearer myMasterKey" \
  | jq

$ curl -s -X POST 'http://localhost:7700/indexes' \
  -H "Authorization: Bearer myMasterKey" \
  -H "Content-Type: application/json" \
  --data '{"uid": "services","primaryKey": "safe_id"}' \
  | jq
```

On peut √† nouveau tenter l'import des donn√©es en pr√©cisant le nouveau fichier **services-clean.json**.

```shell
$ curl -s -X POST 'http://localhost:7700/indexes/services/documents' \
  -H "Authorization: Bearer myMasterKey" \
  -H "Content-Type: application/json" \
  --data-binary @${HOME}/Downloads/services-clean.json \
  | jq
```

üéâ Cette fois-ci, c'est bon !

![Les donn√©es de services apparaissent dans Meilisearch](meilisearch-services-injected.png)

Plus qu'√† faire pareil pour les structures :

```shell
# Pr√©paration des donn√©es
$ node make-services-clean.js \
  --in ~/Downloads/structures-inclusion-2025-08-25.json \
  --out ~/Downloads/structures-clean.json

> OK ‚úÖ  65945 objets trait√©s
‚Üí Fichier √©crit : /Users/jeremy.buget/Downloads/structures-clean.json

# Suppression de l'index
$ curl -s -X DELETE 'http://localhost:7700/indexes/structures' \
  -H "Authorization: Bearer myMasterKey" \
  | jq

> {
  "taskUid": 25,
  "indexUid": "structures",
  "status": "enqueued",
  "type": "indexDeletion",
  "enqueuedAt": "2025-08-28T17:26:13.15551343Z"
}

# Re-cr√©ation de l'index (avec safe_id en 'primaryKey')
$ curl -X POST 'http://localhost:7700/indexes' \
  -H "Authorization: Bearer myMasterKey" \
  -H 'Content-Type: application/json' \
  --data '{"uid":"structures","primaryKey":"safe_id"}' \
  | jq

> {
  "taskUid": 26,
  "indexUid": "structures",
  "status": "enqueued",
  "type": "indexCreation",
  "enqueuedAt": "2025-08-28T17:27:18.49903921Z"
}

# Import des donn√©es
> curl -X POST 'http://localhost:7700/indexes/structures/documents' \
  -H "Authorization: Bearer myMasterKey" \
  -H "Content-Type: application/json" \
  --data-binary @${HOME}/Downloads/structures-clean.json

> {
  "taskUid":27,
  "indexUid":"structures",
  "status":"enqueued",
  "type":"documentAdditionOrUpdate",
  "enqueuedAt":"2025-08-28T17:27:58.287191339Z"
}
```

üöÄ C'est au tour des donn√©es de structures de s'afficher !

![Les donn√©es de structures apparaissent dans Meilisearch](meilisearch-structures-injected.png)

## 5. D√©finir des filtres et facettes

## 6. Activer et configurer la recherche par IA (vectorielle)




## R√©capitulatif des principales requ√™tes utilis√©es

```shell
# Cr√©er un index
$ curl -s -X POST 'http://localhost:7700/indexes' -H "Authorization: Bearer myMasterKey" -H 'Content-Type: application/json' --data '{"uid":"services","primaryKey":"id"}' | jq

# Lister les indexes
$ curl -s -X GET 'localhost:7700/indexes' -H "Authorization: Bearer myMasterKey" | jq

# Supprimer un index
$ curl -s -X POST 'http://localhost:7700/indexes' -H "Authorization: Bearer myMasterKey" -H 'Content-Type: application/json' --data '{"uid":"services","primaryKey":"id"}' | jq

```
