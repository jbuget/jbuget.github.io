---
title: "Faire de la recherche hybride avec Meilisearch"
draft: false
date: "2025-08-28T09:00:00+02:00"
---

Je continue de creuser [**Meilisearch**](https://www.meilisearch.com), le moteur de recherche hybride (full-text et IA-powered) open-source, alternative Ã  Algolia, Typesense et Elasticsearch. Dans cet article, nous allons voir comment dÃ©finir et alimenter un index avec prÃ¨s de 90K documents depuis un fichier de donnÃ©es JSON rÃ©cupÃ©rÃ© sur data.gouv.fr (il y a un peu de taff),  comment mettre en place la recherche mixte (textuelle + vectorielle) et ce que Ã§a donne comme rÃ©sultat.

## 1. Faire tourner une instance Meilisearch avec Docker

```yaml
services:
  meilisearch:
    image: getmeili/meilisearch:v1.19
    container_name: meilisearch
    restart: unless-stopped
    ports:
      - "7700:7700"
    environment:
      MEILI_MASTER_KEY: "myMasterKey"   # Ã  personnaliser
    volumes:
      - meili_data:/meili_data
    command: meilisearch --experimental-dumpless-upgrade

volumes:
  meili_data:
```

Dans Meilisearch (version Community Edition), toute l'administration se passe en ligne de commande (CLI ou API HTTP). Personnellement, mon moyen de prÃ©dilection est de faire des requÃªtes HTTP avec `cURL` et `jq` (pour formatter et manipuler les donnÃ©es JSON en rÃ©ponse).

> ðŸ’¡ Avec cURL, j'utilise l'option `-s | --silent` afin de ne pas Ãªtre polluÃ© par les informations de progression de rÃ©cupÃ©ration des donnÃ©es.

Pour toute requÃªte de l'API Meilisearch, il faut passer la master key en header `AUTHORIZATION` #sÃ©curitÃ©.
{.pros}

```shell
$ curl -s -X GET 'localhost:7700/indexes' \
  -s -H "Authorization: Bearer myMasterKey" \
  | jq

> {
  "results": [
    {
      "uid": "services",
      "createdAt": "2025-08-28T10:34:15.425435597Z",
      "updatedAt": "2025-08-28T10:34:43.891700971Z",
      "primaryKey": "safe_id"
    }
  ],
  "offset": 0,
  "limit": 20,
  "total": 1
}
```




## 2. RÃ©cupÃ©rer les donnÃ©es

Pour notre cas d'Ã©tude, j'ai dÃ©cidÃ© d'exploiter des donnÃ©es que je connais bien : l'ensemble des **services d'insertion socio-professionnelles** â€“ alias "offre des services de l'inclusion" â€“ rÃ©fÃ©rencÃ©s par la Plateforme de l'inclusion, et rÃ©guliÃ¨rement mis Ã  jour et Ã  disposition dans la plateforme de l'Ã©tat data.gouv.fr (cf. lien vers le fichier de donnÃ©es). Pour complÃ©ter un peu plus l'expÃ©rience et aller un cran plus loin, je vais aussi rÃ©cupÃ©rer les donnÃ©es des **structures de l'inclusion**.

Les 2 sources de donnÃ©es en question :
* [liste des services](https://www.data.gouv.fr/datasets/referentiel-de-loffre-dinsertion-sociale-et-professionnelle-data-inclusion/#/resources/0eac1faa-66f9-4e49-8fb3-f0721027d89f) â€“ +80K documents / 235Mo
  * **~/Downloads/services-inclusion-2025-08-25.json**
* [liste des structures](https://www.data.gouv.fr/datasets/referentiel-de-loffre-dinsertion-sociale-et-professionnelle-data-inclusion/#/resources/0eac1faa-66f9-4e49-8fb3-f0721027d89f) â€“ +60K documents / 101Mo
  * **~/Downloads/structures-inclusion-2025-08-25.json**

![DonnÃ©es de dataÂ·inclusion depuis data.gouv.fr](data-gouv-di-services.png)

## 3. DÃ©clarer les indexes

Ã€ ce stade, nous disposons du contenant (Meilisearch) et d'un contenu (gros fichier JSON). Le prochain objectif est d'injecter les donnÃ©es (services et structures) dans le systÃ¨me.

Pour cela, nous dÃ©finissons 2 indexes : `/services` et `structures`.

> ðŸ’¡ Dans Meilisearch (et plus gÃ©nÃ©ralement dans les systÃ¨mes de moteur de recherche), **un index est une base de donnÃ©es optimisÃ©e pour la recherche, qui regroupe des documents partageant la mÃªme structure** et sur laquelle on exÃ©cute les requÃªtes full-text, vectorielles ou hybrides.

Dans Meilisearch (version Community Edition), toute l'administration se passe en ligne de commande (CLI ou requÃªtes HTTP / cURL). Personnellement, je passe pas

De faÃ§on pratique, Meilisearch crÃ©Ã©e automatiquement un index s'il n'existe pas au moment d'injecter des documents. Personnellement, je prÃ©fÃ¨re dÃ©clarer les indexes moi-mÃªme, car je prÃ©fÃ¨re avoir le contrÃ´le et que dÃ¨s que l'on utilise rÃ©ellement la solution, il faut le plus souvent, Ã  un moment ou un autre, paramÃ©trer l'index.
{.pros}

La commande pour **dÃ©clarer un index** :

```shell
$ curl -s -X POST 'http://localhost:7700/indexes' \
  -H "Authorization: Bearer myMasterKey" \
  -H 'Content-Type: application/json' \
  --data '{"uid":"services","primaryKey":"id"}' \
  | jq

> {
  "taskUid": 19,
  "indexUid": "services",
  "status": "enqueued",
  "type": "indexCreation",
  "enqueuedAt": "2025-08-28T16:08:21.677341712Z"
}
```

En cas de problÃ¨me ou d'erreur, il est possible de **supprimer un index** grÃ¢ce Ã  la ressource `DELETE /indexes/{index_name}` :

```shell
$ curl -s -X DELETE 'http://localhost:7700/indexes/services' \
  -H "Authorization: Bearer myMasterKey" \
  | jq

> {
  "taskUid": 16,
  "indexUid": "services",
  "status": "enqueued",
  "type": "indexDeletion",
  "enqueuedAt": "2025-08-28T16:03:56.477857464Z"
}
```

AprÃ¨s la crÃ©ation des 2 indexes, le listing des indexes devrait ressembler Ã  :

```shell
$ curl -s -X GET 'localhost:7700/indexes' -H "Authorization: Bearer myMasterKey" | jq

> {
  "results": [
    {
      "uid": "services",
      "createdAt": "2025-08-28T16:08:21.680481753Z",
      "updatedAt": "2025-08-28T16:08:21.685127462Z",
      "primaryKey": "id"
    },
    {
      "uid": "structures",
      "createdAt": "2025-08-28T16:08:13.975849291Z",
      "updatedAt": "2025-08-28T16:08:13.983862708Z",
      "primaryKey": "id"
    }
  ],
  "offset": 0,
  "limit": 20,
  "total": 2
}
```

Tout est prÃªt pour importer notre premier jeu de donnÃ©es, les services.

## 4. Injecter les donnÃ©es

Pour **injecter des documents dans un index**, il faut utiliser la commande :

```shell
$ curl -X POST 'http://localhost:7700/indexes/services/documents' \
  -H "Authorization: Bearer myMasterKey" \
  -H 'Content-Type: application/json' \
  --data-binary "@${HOME}/Downloads/services-inclusion-2025-08-25.json" \
  | jq

> {
  "taskUid": 21,
  "indexUid": "services",
  "status": "enqueued",
  "type": "documentAdditionOrUpdate",
  "enqueuedAt": "2025-08-28T16:20:26.170638547Z"
}
```

Toujours dans un souci de simplifier la vie des dÃ©veloppeurs, Meilisearch tente de dÃ©tecter un champs ID pour en faire la `primaryKey` de l'index. Il se trouve que le schÃ©ma de notre jeu de donnÃ©es possÃ¨de dÃ©jÃ  un champs ID. Tout devrait bien se passer. Pour s'en assurer, on peut lire le dÃ©but du fichier de donnÃ©es :
{.pros}

```shell
$ head -c 1000 ~/Downloads/services-inclusion-2025-08-25.json

> [{"id":"Mednum-BFC_mednumBFC_TL_206_-mediation-numerique","structure_id":"Mednum-BFC_mednumBFC_TL_206_","source":"mediation-numerique","nom":"MÃ©diation numÃ©rique","presentation_resume":"Le V  FourmiliÃ¨re des Savoir-Faire propose des services : numÃ©rique, accompagner les dÃ©marches de santÃ©, devenir autonome dans les dÃ©marches administratives, rÃ©aliser des dÃ©marches administratives avec un accompagnement.","presentation_detail":"Le V  FourmiliÃ¨re des Savoir-Faire propose des services : numÃ©rique, accompagner les dÃ©marches de santÃ©, devenir autonome dans les dÃ©marches administratives, rÃ©aliser des dÃ©marches administratives avec un accompagnement.","types":["accompagnement"],"thematiques":["numerique","numerique--realiser-des-demarches-administratives-avec-un-accompagnement","numerique--devenir-autonome-dans-les-demarches-administratives","numerique--accompagner-les-demarches-de-sante"],"prise_rdv":null,"frais":[],"frais_autres":null,"profils":[],"profils_precisions":null,"%
```

La commande `POST /indexes/services/documents` s'est finie sans afficher aucune erreur. On pourrait donc se satisfaire que tout a fonctionnÃ© du premier coup. Malheureusement, ce n'est pas le cas ðŸ˜©.

Chaque opÃ©ration effectuÃ©e dans Meilisearch prend la forme d'une `Task`, avec diffÃ©rents statuts, qu'il est possible de suivre :

```shell
$ curl -s -X GET 'localhost:7700/tasks' -H "Authorization: Bearer myMasterKey" | jq

> {
  "results": [
    {
      "uid": 21,
      "batchUid": 19,
      "indexUid": "services",
      "status": "failed",
      "type": "documentAdditionOrUpdate",
      "canceledBy": null,
      "details": {
        "receivedDocuments": 86670,
        "indexedDocuments": 0
      },
      "error": {
        "message": "Document identifier `\"Coop-numÃ©rique_1a162d63-e303-4fdc-aa08-71d47634b1ff-mediation-numerique\"` is invalid. A document identifier can be of type integer or string, only composed of alphanumeric characters (a-z A-Z 0-9), hyphens (-) and underscores (_), and can not be more than 511 bytes.",
        "code": "invalid_document_id",
        "type": "invalid_request",
        "link": "https://docs.meilisearch.com/errors#invalid_document_id"
      },
      "duration": "PT0.001194792S",
      "enqueuedAt": "2025-08-28T16:20:26.170638547Z",
      "startedAt": "2025-08-28T16:20:26.17297113Z",
      "finishedAt": "2025-08-28T16:20:26.174165922Z"
    },
    # ...
  ]
}
```

âŒ Il y a eu un souci lors de l'import des donnÃ©es. L'une des entrÃ©es possÃ¨de des accents dans son ID.

Pas le choix, il faut faire un script pour "adapter les donnÃ©es". Je n'ai pas envie de me prendre la tÃªte, je demande Ã  Claude de me le crÃ©er, en Node.js. PrÃ©cisÃ©ment, je lui demande de gÃ©nÃ©rer un `safe_id` de type UUID pour chacun des objets "services".

```javascript
#!/usr/bin/env node
/**
 * make-services-clean.js
 * Lit un gros JSON (tableau) en streaming, ajoute safe_id=UUIDv4 Ã  chaque objet,
 * et produit un nouveau fichier JSON (tableau) sans charger tout le fichier en RAM.
 *
 * Usage:
 *   node make-services-clean.js \
 *     --in ~/Downloads/services-inclusion-2025-08-25.json \
 *     --out ~/Downloads/services-clean.json
 */

const fs = require('fs');
const path = require('path');
const { pipeline } = require('stream');
const { randomUUID } = require('crypto');
const { parser } = require('stream-json');
const { streamArray } = require('stream-json/streamers/StreamArray');

function expandHome(p) {
  if (p.startsWith('~/')) return path.join(process.env.HOME || process.env.USERPROFILE || '', p.slice(2));
  return p;
}

function getArg(flag, def = null) {
  const idx = process.argv.indexOf(flag);
  return idx !== -1 && process.argv[idx + 1] ? process.argv[idx + 1] : def;
}

const inPath = expandHome(getArg('--in', '~/Downloads/services-inclusion-2025-08-25.json'));
const outPath = expandHome(getArg('--out', '~/Downloads/services-clean.json'));

// VÃ©rifs rapides
if (!fs.existsSync(inPath)) {
  console.error(`Fichier introuvable: ${inPath}`);
  process.exit(1);
}

// Flux lecture JSON + parseur + streamer d'Ã©lÃ©ments de tableau
const readStream = fs.createReadStream(inPath, { encoding: 'utf8' });
const jsonParser = parser();
const arrayStreamer = streamArray();

// Ã‰criture en flux du tableau de sortie
const writeStream = fs.createWriteStream(outPath, { encoding: 'utf8' });

// On Ã©crit l'ouverture du tableau
writeStream.write('[');

let first = true;
let count = 0;

// Ã€ chaque Ã©lÃ©ment {key, value} du tableau d'entrÃ©e
arrayStreamer.on('data', ({ value }) => {
  // Ajout dâ€™un UUID v4
  value.safe_id = randomUUID();

  // Ã‰crire la virgule entre Ã©lÃ©ments (sauf le premier)
  if (!first) {
    writeStream.write(',');
  } else {
    first = false;
  }

  // Ã‰criture compacte pour limiter la taille du fichier
  writeStream.write(JSON.stringify(value));
  count++;
});

// Gestion fin et erreurs
arrayStreamer.on('end', () => {
  writeStream.write(']');
  writeStream.end(() => {
    console.log(`OK âœ…  ${count} objets traitÃ©s`);
    console.log(`â†’ Fichier Ã©crit : ${outPath}`);
  });
});

arrayStreamer.on('error', (err) => {
  console.error('Erreur streamArray:', err);
  process.exit(1);
});

jsonParser.on('error', (err) => {
  console.error('Erreur parser JSON:', err);
  process.exit(1);
});

writeStream.on('error', (err) => {
  console.error('Erreur Ã©criture fichier:', err);
  process.exit(1);
});

// ChaÃ®ner les streams
pipeline(readStream, jsonParser, arrayStreamer, (err) => {
  if (err) {
    console.error('Erreur pipeline:', err);
    process.exit(1);
  }
});
```


Pour l'exÃ©cution :

```shell
# 1. On installe les dÃ©pendances npm
$ npm i stream-json

# 2. On exÃ©cute le programme
$ node make-services-clean.js \
  --in ~/Downloads/services-inclusion-2025-08-25.json \
  --out ~/Downloads/services-clean.json

> OK âœ…  86670 objets traitÃ©s
â†’ Fichier Ã©crit : /Users/vous/Downloads/services-clean.json
```

âš ï¸ Il faut regÃ©nÃ©rer l'index "services" :

```shell
$ curl -s -X DELETE 'http://localhost:7700/indexes/services' \
  -H "Authorization: Bearer myMasterKey" \
  | jq

$ curl -s -X POST 'http://localhost:7700/indexes' \
  -H "Authorization: Bearer myMasterKey" \
  -H "Content-Type: application/json" \
  --data '{"uid": "services","primaryKey": "safe_id"}' \
  | jq
```

On peut Ã  nouveau tenter l'import des donnÃ©es en prÃ©cisant le nouveau fichier **services-clean.json**.

```shell
$ curl -s -X POST 'http://localhost:7700/indexes/services/documents' \
  -H "Authorization: Bearer myMasterKey" \
  -H "Content-Type: application/json" \
  --data-binary @${HOME}/Downloads/services-clean.json \
  | jq
```

ðŸŽ‰ Cette fois-ci, c'est bon !

![Les donnÃ©es de services apparaissent dans Meilisearch](meilisearch-services-injected.png)

Plus qu'Ã  faire pareil pour les structures :

```shell
# PrÃ©paration des donnÃ©es
$ node make-services-clean.js \
  --in ~/Downloads/structures-inclusion-2025-08-25.json \
  --out ~/Downloads/structures-clean.json

> OK âœ…  65945 objets traitÃ©s
â†’ Fichier Ã©crit : /Users/jeremy.buget/Downloads/structures-clean.json

# Suppression de l'index
$ curl -s -X DELETE 'http://localhost:7700/indexes/structures' \
  -H "Authorization: Bearer myMasterKey" \
  | jq

> {
  "taskUid": 25,
  "indexUid": "structures",
  "status": "enqueued",
  "type": "indexDeletion",
  "enqueuedAt": "2025-08-28T17:26:13.15551343Z"
}

# Re-crÃ©ation de l'index (avec safe_id en 'primaryKey')
$ curl -X POST 'http://localhost:7700/indexes' \
  -H "Authorization: Bearer myMasterKey" \
  -H 'Content-Type: application/json' \
  --data '{"uid":"structures","primaryKey":"safe_id"}' \
  | jq

> {
  "taskUid": 26,
  "indexUid": "structures",
  "status": "enqueued",
  "type": "indexCreation",
  "enqueuedAt": "2025-08-28T17:27:18.49903921Z"
}

# Import des donnÃ©es
> curl -X POST 'http://localhost:7700/indexes/structures/documents' \
  -H "Authorization: Bearer myMasterKey" \
  -H "Content-Type: application/json" \
  --data-binary @${HOME}/Downloads/structures-clean.json

> {
  "taskUid":27,
  "indexUid":"structures",
  "status":"enqueued",
  "type":"documentAdditionOrUpdate",
  "enqueuedAt":"2025-08-28T17:27:58.287191339Z"
}
```

ðŸš€ C'est au tour des donnÃ©es de structures de s'afficher !

![Les donnÃ©es de structures apparaissent dans Meilisearch](meilisearch-structures-injected.png)

## 5. DÃ©finir des filtres et facettes

## 6. Activer et configurer la recherche par IA (vectorielle)




## RÃ©capitulatif des principales requÃªtes utilisÃ©es

```shell
# CrÃ©er un index
$ curl -s -X POST 'http://localhost:7700/indexes' -H "Authorization: Bearer myMasterKey" -H 'Content-Type: application/json' --data '{"uid":"services","primaryKey":"id"}' | jq

# Lister les indexes
$ curl -s -X GET 'localhost:7700/indexes' -H "Authorization: Bearer myMasterKey" | jq

# Supprimer un index
$ curl -s -X POST 'http://localhost:7700/indexes' -H "Authorization: Bearer myMasterKey" -H 'Content-Type: application/json' --data '{"uid":"services","primaryKey":"id"}' | jq

```
